{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [IAPR 2019:][iapr2019] Special project\n",
    "\n",
    "**Group members:**\n",
    "    1- first name and last name,\n",
    "    2- first name and last name,\n",
    "    3- first name and last name\n",
    "\n",
    "**Due date:** 30.05.2019\n",
    "\n",
    "[iapr2019]: https://github.com/LTS5/iapr-2019\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "Please find the description of this special project via [this link].\n",
    "\n",
    "[this link]: https://github.com/LTS5/iapr-2019/blob/master/project/special_project_description.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import os\n",
    "from PIL import Image, ImageDraw\n",
    "import math\n",
    "import cv2 \n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train image size 800 , test image size 50, validation image size 150\n"
     ]
    }
   ],
   "source": [
    "src_path_train = './project-data/images/train/'\n",
    "xml_path_train=\"./project-data/annotations/train/\"\n",
    "prepared_data_path=\"./project-data/images/train/prepared_data/\"\n",
    "img_list_dir = os.listdir(src_path_train)\n",
    "img_list = [names for names in img_list_dir if names.endswith(\".jpg\")]\n",
    "img_list_size = len(img_list)\n",
    "\n",
    "src_path_test = './project-data/images/test/'\n",
    "xml_path_test=\"./project-data/annotations/test/\"\n",
    "prepared_data_path_test=\"./project-data/images/test/prepared_data/\"\n",
    "img_list_dir_test = os.listdir(src_path_test)\n",
    "img_list_test = [names for names in img_list_dir_test  if names.endswith(\".jpg\")]\n",
    "img_list_size_test = len(img_list_test)\n",
    "\n",
    "src_path_validation = './project-data/images/validation/'\n",
    "xml_path_validation=\"./project-data/annotations/validation/\"\n",
    "prepared_data_path_validation=\"./project-data/images/validation/prepared_data/\"\n",
    "img_list_dir_validation = os.listdir(src_path_validation)\n",
    "img_list_validation = [names for names in img_list_dir_validation  if names.endswith(\".jpg\")]\n",
    "img_list_size_validation = len(img_list_validation)\n",
    "print(\"train image size {} , test image size {}, validation image size {}\".format(img_list_size,img_list_size_test,img_list_size_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_file(filename):\n",
    "    \"\"\" Parse a PASCAL VOC xml file \"\"\"\n",
    "    tree = ET.parse(filename)\n",
    "    objects = []\n",
    "    for obj in tree.findall('object'):\n",
    "        obj_struct = {}\n",
    "        obj_struct['name'] = obj.find('name').text\n",
    "        bbox = obj.find('bndbox')\n",
    "        obj_struct['bbox'] = [int(float(bbox.find('xmin').text)),\n",
    "                              int(float(bbox.find('ymin').text)),\n",
    "                              int(float(bbox.find('xmax').text))-int(float(bbox.find('xmin').text)),\n",
    "                              int(float(bbox.find('ymax').text))-int(float(bbox.find('ymin').text))]\n",
    "        objects.append(obj_struct)\n",
    "    return objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_xmls = [parse_file(os.path.join(xml_path_train, name[:-4]) + '.xml') for name in img_list]\n",
    "annotations_xmls_test=[parse_file(os.path.join(xml_path_test, name[:-4]) + '.xml') for name in img_list_test]\n",
    "annotations_xmls_validation=[parse_file(os.path.join(xml_path_validation, name[:-4]) + '.xml') for name in img_list_validation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_IOU(bbox1, bbox2):\n",
    "    #Calculate overlap between two bounding boxes [x, y, w, h] as the area of intersection over the area of unity\n",
    "    \n",
    "    #determine the (x, y)-coordinates of the intersection rectangle\n",
    "    x1, y1, w1, h1 = bbox1[0], bbox1[1], bbox1[2], bbox1[3]\n",
    "    x2, y2, w2, h2 = bbox2[0], bbox2[1], bbox2[2], bbox2[3]\n",
    "    \n",
    "    \n",
    "    xA = max(x1, x2)\n",
    "    yA = max(y1, y2)\n",
    "    xB = min(x1+w1, x2+w2)\n",
    "    yB = min(y1+h1, y2+h2)\n",
    "    # compute the area of intersection rectangle\n",
    "    interArea = max(0, xB - xA ) * max(0, yB - yA )\n",
    "    \n",
    "    # compute the area of both the prediction and ground-truth\n",
    "    boxAArea = (w1 ) * (h1 )\n",
    "    boxBArea = (w2 ) * (h2 )\n",
    "\n",
    "    # compute the intersection over union by taking the intersection\n",
    "    # area and dividing it by the sum of prediction + ground-truth\n",
    "    # areas - the interesection area\n",
    "    iou = interArea / float(boxAArea + boxBArea - interArea)\n",
    "\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_and_label(prepared_data_path,img,img_name,annotations): \n",
    "    #Mirror padding\n",
    "    w,h,d = img.shape \n",
    "    w_i=int(w/32)+1\n",
    "    h_i=int(h/32)+1\n",
    "    new_w=w_i*32\n",
    "    new_h=h_i*32\n",
    "    count=0\n",
    "    new_img=img\n",
    "    l=0\n",
    "    for i in range(w_i): \n",
    "        for j in range(h_i): \n",
    "            count+=1 \n",
    "            name=img_name+\"_\"+str(count)\n",
    "            sub_img=new_img[0:64,0:64,:]\n",
    "            label=0\n",
    "            for box in annotations:\n",
    "                if (box[0]>=i*32  and box[0]< i*32+64 and box[1]>=j*32 and  box[1]< j*32+64) :\n",
    "                    if ( box[0]+box[2]<i*32+64 and box[1]+box[3]<j*32+64):\n",
    "                        l=l+1\n",
    "                        label=1\n",
    "                \"\"\"\"\n",
    "                iou=calculate_IOU(box,[i*32,j*32,64,64])\n",
    "                if (iou>0.5): \n",
    "                    label=1 \n",
    "                    j=j+1\n",
    "                    break\n",
    "                \"\"\"\n",
    "            name+=\"_\"+str(label)\n",
    "            im=Image.fromarray(sub_img)\n",
    "            b, g, r = im.split()\n",
    "            im= Image.merge(\"RGB\", (r, g, b))\n",
    "            im.save(prepared_data_path+name+\".jpg\")         \n",
    "            new_img=np.roll(new_img,-32,axis=1)\n",
    "        new_img=np.roll(new_img,-32,axis=0)\n",
    "    return l "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train max box size [56] , test max box size [52], validation max box size [52]\n"
     ]
    }
   ],
   "source": [
    "ground_truth_1=[]\n",
    "for j in range(len(annotations_xmls)):\n",
    "    for i in range(len(annotations_xmls[j])): \n",
    "        ground_truth_1.append(annotations_xmls[j][i]['bbox'][2:3])\n",
    "max_box_size=max(ground_truth_1)\n",
    "ground_truth_1=[]\n",
    "\n",
    "for j in range(len(annotations_xmls_test)):\n",
    "    for i in range(len(annotations_xmls_test[j])): \n",
    "        ground_truth_1.append(annotations_xmls_test[j][i]['bbox'][2:3])\n",
    "max_box_size_test=max(ground_truth_1)\n",
    "\n",
    "for j in range(len(annotations_xmls_validation)):\n",
    "    for i in range(len(annotations_xmls_validation[j])): \n",
    "        ground_truth_1.append(annotations_xmls_validation[j][i]['bbox'][2:3])\n",
    "max_box_size_validation=max(ground_truth_1)\n",
    "print(\"train max box size {} , test max box size {}, validation max box size {}\".format(max_box_size,max_box_size_test,max_box_size_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def split_and_label_v2(prepared_data_path,max_box_size,img,img_name,annotations): \n",
    "    count=0\n",
    "    width,height=img.shape[0],img.shape[1]\n",
    "    bbox=[]\n",
    "    for box in annotations: \n",
    "        name=img_name+\"_\"+str(count)+\"_1\"\n",
    "\n",
    "        xmin,ymin,w,h=box[0],box[1],box[2],box[3] \n",
    "        max_size=int(max_box_size[0]/2)\n",
    "        new_img_=img[max(0,ymin-10):min(ymin+max_size+10,width),max(0,xmin-10):min(xmin+max_size+10,height),:]\n",
    "        im=Image.fromarray(new_img_)\n",
    "        bbox.append([10,10,box[2],box[3],1])\n",
    "        b, g, r = im.split()\n",
    "        im= Image.merge(\"RGB\", (r, g, b))\n",
    "        im.save(prepared_data_path+name+\".jpg\") \n",
    "        name=img_name+\"_\"+str(count)+\"_0\"\n",
    "        if (xmin-56)>0 and (ymin-56)>0:\n",
    "            x1 = random.randint(0, xmin-56)\n",
    "            y1 = random.randint(0, ymin-56)\n",
    "        else :\n",
    "            x1 = random.randint(0, min(xmin+56,height))\n",
    "            y1 = random.randint(0, min(ymin+56,width))\n",
    "        new_img=img[y1:min(y1+48,width),x1:min(height,x1+48),:]\n",
    "        bbox.append([0,0,0,0,0])\n",
    "        im=Image.fromarray(new_img)\n",
    "        b, g, r = im.split()\n",
    "        im= Image.merge(\"RGB\", (r, g, b))\n",
    "        im.save(prepared_data_path+name+\".jpg\") \n",
    "        count+=1\n",
    "    return bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(img_list,src_path,max_box_size,prepared_data_path,annotations_xmls):\n",
    "    bbox=[]\n",
    "    for j in range(len(img_list)):\n",
    "        name=img_list[j]\n",
    "        img = cv2.imread(src_path+name)\n",
    "        ground_truth_1=[]\n",
    "        for i in range(len(annotations_xmls[j])): \n",
    "            ground_truth_1.append(annotations_xmls[j][i]['bbox'])\n",
    "        ground_truth_1\n",
    "        bbox.append(split_and_label_v2(prepared_data_path,max_box_size,img,name[:-4],ground_truth_1))\n",
    "    return bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "print(len(annotations_xmls_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox=make_dataset(img_list,src_path_train,max_box_size,prepared_data_path,annotations_xmls)\n",
    "bbox_test=make_dataset(img_list_test,src_path_test,max_box_size_test,prepared_data_path_test,annotations_xmls_test)\n",
    "bbox_validation=make_dataset(img_list_validation,src_path_validation,max_box_size_validation,prepared_data_path_validation,annotations_xmls_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOR TRAINING\n",
      "number of images with label =1 (varroas) is  7483\n",
      "number of images with label =0 (non varroas) is  7483\n",
      "Total number of files =  14966\n",
      "FOR TESTING\n",
      "number of images with label =1 (varroas) is  582\n",
      "number of images with label =0 (non varroas) is  582\n",
      "Total number of files =  1164\n",
      "FOR VALIDATION\n",
      "number of images with label =1 (varroas) is  1539\n",
      "number of images with label =0 (non varroas) is  1539\n",
      "Total number of files =  3078\n"
     ]
    }
   ],
   "source": [
    "img_list_dir_prep = os.listdir(prepared_data_path)\n",
    "number_label_non_varroa_train=0\n",
    "number_label_varroa_train=0\n",
    "for prep_name in img_list_dir_prep: \n",
    "    if prep_name.endswith('_1.jpg'):\n",
    "        number_label_varroa_train+=1\n",
    "    if prep_name.endswith('_0.jpg'):\n",
    "        number_label_non_varroa_train+=1\n",
    "print(\"FOR TRAINING\")\n",
    "print(\"number of images with label =1 (varroas) is \",number_label_non_varroa_train)\n",
    "print(\"number of images with label =0 (non varroas) is \",number_label_varroa_train)\n",
    "print(\"Total number of files = \",number_label_varroa_train+number_label_non_varroa_train)    \n",
    "\n",
    "img_list_dir_prep_test = os.listdir(prepared_data_path_test)\n",
    "number_label_non_varroa_test=0\n",
    "number_label_varroa_test=0\n",
    "for prep_name in img_list_dir_prep_test: \n",
    "    if prep_name.endswith('_1.jpg'):\n",
    "        number_label_varroa_test+=1\n",
    "    if prep_name.endswith('_0.jpg'):\n",
    "        number_label_non_varroa_test+=1\n",
    "print(\"FOR TESTING\")\n",
    "print(\"number of images with label =1 (varroas) is \",number_label_non_varroa_test)\n",
    "print(\"number of images with label =0 (non varroas) is \",number_label_varroa_test)\n",
    "print(\"Total number of files = \",number_label_varroa_test+number_label_non_varroa_test)\n",
    "\n",
    "img_list_dir_prep_validation = os.listdir(prepared_data_path_validation)\n",
    "number_label_non_varroa_val=0\n",
    "number_label_varroa_val=0\n",
    "for prep_name in img_list_dir_prep_validation: \n",
    "    if prep_name.endswith('_1.jpg'):\n",
    "        number_label_varroa_val+=1\n",
    "    if prep_name.endswith('_0.jpg'):\n",
    "        number_label_non_varroa_val+=1\n",
    "print(\"FOR VALIDATION\")\n",
    "print(\"number of images with label =1 (varroas) is \",number_label_non_varroa_val)\n",
    "print(\"number of images with label =0 (non varroas) is \",number_label_varroa_val)\n",
    "print(\"Total number of files = \",number_label_varroa_val+number_label_non_varroa_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize(img_list_dir_prep,prepared_data_path):\n",
    "    img_list_prep = [names for names in img_list_dir_prep if names.endswith(\".jpg\")]\n",
    "    sizes = [Image.open(prepared_data_path+f, 'r').size for f in img_list_prep]\n",
    "    max_width,max_height=max(sizes)\n",
    "    for item in img_list_dir_prep:\n",
    "        if os.path.isfile(prepared_data_path+item):\n",
    "            im = Image.open(prepared_data_path+item)\n",
    "            f, e = os.path.splitext(prepared_data_path+item)\n",
    "            imResize = im.resize((48,48), Image.ANTIALIAS)\n",
    "            imResize.save(f + '.jpg', 'JPEG', quality=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize(img_list_dir_prep,prepared_data_path)\n",
    "resize(img_list_dir_prep_test,prepared_data_path_test)\n",
    "resize(img_list_dir_prep_validation,prepared_data_path_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list_prep_train = [names for names in img_list_dir_prep if names.endswith(\".jpg\")]\n",
    "img_list_prep_test = [names for names in img_list_dir_prep_test if names.endswith(\".jpg\")]\n",
    "img_list_prep_validation = [names for names in img_list_dir_prep_validation if names.endswith(\".jpg\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_imgs_train=number_label_varroa_train+number_label_non_varroa_train\n",
    "num_imgs_test=number_label_varroa_test+number_label_non_varroa_test\n",
    "num_imgs_validation=number_label_varroa_val+number_label_non_varroa_val\n",
    "\n",
    "X_train=np.zeros((num_imgs_train,48,48,3))\n",
    "for i in range(len(img_list_prep_train)):\n",
    "    name=img_list_prep_train[i]\n",
    "    img = cv2.imread(prepared_data_path+name)\n",
    "    X_train[i,:,:,:]=img\n",
    "\n",
    "X_test=np.zeros((num_imgs_test,48,48,3))\n",
    "for i in range(len(img_list_prep_test)):\n",
    "    name=img_list_prep_test[i]\n",
    "    img = cv2.imread(prepared_data_path_test+name)\n",
    "    X_test[i,:,:,:]=img\n",
    "\n",
    "X_val=np.zeros((num_imgs_validation,48,48,3))\n",
    "for i in range(len(img_list_prep_validation)):\n",
    "    name=img_list_prep_validation[i]\n",
    "    img = cv2.imread(prepared_data_path_validation+name)\n",
    "    X_val[i,:,:,:]=img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14966, 48, 48, 3)\n",
      "(1164, 48, 48, 3)\n",
      "(3078, 48, 48, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "bbox_train_=np.zeros((X_train.shape[0],5))\n",
    "for image_box in bbox: \n",
    "    for box in image_box:\n",
    "        bbox_train_[count,0]=box[0]\n",
    "        bbox_train_[count,1]=box[1]\n",
    "        bbox_train_[count,2]=box[2]\n",
    "        bbox_train_[count,3]=box[3]\n",
    "        bbox_train_[count,4]=box[4]\n",
    "        count+=1  \n",
    "\n",
    "count=0\n",
    "bbox_test_=np.zeros((X_test.shape[0],5))\n",
    "for image_box in bbox_test: \n",
    "    for box in image_box:\n",
    "        bbox_test_[count,0]=box[0]\n",
    "        bbox_test_[count,1]=box[1]\n",
    "        bbox_test_[count,2]=box[2]\n",
    "        bbox_test_[count,3]=box[3]\n",
    "        bbox_test_[count,4]=box[4]\n",
    "        count+=1  \n",
    "\n",
    "count=0\n",
    "bbox_validation_=np.zeros((X_val.shape[0],5))\n",
    "for image_box in bbox_validation: \n",
    "    for box in image_box:\n",
    "        bbox_validation_[count,0]=box[0]\n",
    "        bbox_validation_[count,1]=box[1]\n",
    "        bbox_validation_[count,2]=box[2]\n",
    "        bbox_validation_[count,3]=box[3]\n",
    "        bbox_validation_[count,4]=box[4]\n",
    "        count+=1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train=bbox_train_\n",
    "Y_test=bbox_test_\n",
    "Y_val=bbox_validation_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "num_epoch = 10\n",
    "learning_rate = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (hidden): Linear(in_features=1152, out_features=256, bias=True)\n",
      "  (box): Linear(in_features=256, out_features=4, bias=True)\n",
      "  (logit): Linear(in_features=256, out_features=1, bias=True)\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(3, 8, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(8, 16, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (conv3): Sequential(\n",
      "    (0): Conv2d(16, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# define network architecture\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, n_feature, n_hidden, n_output, n_c):\n",
    "        super(Net, self).__init__()\n",
    "        self.hidden = torch.nn.Linear(n_feature, n_hidden)   # hidden layer\n",
    "        self.box = torch.nn.Linear(n_hidden, n_output-1)   # output layer\n",
    "        self.logit = torch.nn.Linear(n_hidden, 1)\n",
    "        \n",
    "        self.conv1 = torch.nn.Sequential(         # \n",
    "            torch.nn.Conv2d(\n",
    "                in_channels = n_c,            # input height\n",
    "                out_channels = 8,             # n_filters\n",
    "                kernel_size = 2,              # filter size\n",
    "                stride = 2,                   # filter movement/step\n",
    "                padding = 0,                  \n",
    "            ),                              \n",
    "            torch.nn.ReLU(),                      # activation\n",
    "            #torch.nn.MaxPool2d(kernel_size = 2),    \n",
    "        )\n",
    "        self.conv2 = torch.nn.Sequential(       \n",
    "            torch.nn.Conv2d(in_channels = 8, \n",
    "                            out_channels = 16, \n",
    "                            kernel_size = 2, \n",
    "                            stride = 2, \n",
    "                            padding = 0),      \n",
    "            torch.nn.ReLU(),                      # activation\n",
    "            #torch.nn.MaxPool2d(2),                \n",
    "        )\n",
    "        \n",
    "        self.conv3 = torch.nn.Sequential(       \n",
    "            torch.nn.Conv2d(in_channels = 16, \n",
    "                            out_channels = 8, \n",
    "                            kernel_size = 1, \n",
    "                            stride = 1, \n",
    "                            padding = 0),      \n",
    "            torch.nn.ReLU(),                      # activation\n",
    "            #torch.nn.MaxPool2d(2),                \n",
    "        )\n",
    "    def forward(self, x):\n",
    "        feat = self.conv1(x)\n",
    "        feat = self.conv2(feat)\n",
    "       \n",
    "        feat = self.conv3(feat)\n",
    "        feat = feat.view(feat.size(0), -1)\n",
    "        \n",
    "        x2 = F.relu(self.hidden(feat))      # activation function for hidden layer\n",
    "       \n",
    "        out_box = F.relu(self.box(x2))            # linear output\n",
    "        out_logit = torch.sigmoid(self.logit(x2))\n",
    "        \n",
    "        return out_box, out_logit\n",
    "      \n",
    "net = Net(n_feature = 1152, n_hidden = 256, n_output = 5, n_c = 3)     # define the network\n",
    "print(net)  # net architecture\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_criterion =  torch.nn.MSELoss()\n",
    "classification_criterion =  torch.nn.BCELoss()# Hint: Consider that we only one class to predict\n",
    "gamma =0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0  Total loss -> 13.25483   classif_loss -> 0.45155  regress_loss -> 14.67742\n",
      "epoch: 1  Total loss -> 9.41509   classif_loss -> 0.37795  regress_loss -> 10.41922\n",
      "epoch: 2  Total loss -> 10.13451   classif_loss -> 0.32755  regress_loss -> 11.22417\n",
      "epoch: 3  Total loss -> 10.67117   classif_loss -> 0.28011  regress_loss -> 11.82574\n",
      "epoch: 4  Total loss -> 10.99352   classif_loss -> 0.24921  regress_loss -> 12.18733\n",
      "epoch: 5  Total loss -> 11.17108   classif_loss -> 0.23658  regress_loss -> 12.38602\n",
      "epoch: 6  Total loss -> 11.76861   classif_loss -> 0.24594  regress_loss -> 13.04890\n",
      "epoch: 7  Total loss -> 11.65050   classif_loss -> 0.21178  regress_loss -> 12.92147\n",
      "epoch: 8  Total loss -> 11.39344   classif_loss -> 0.22867  regress_loss -> 12.63397\n",
      "epoch: 9  Total loss -> 11.22220   classif_loss -> 0.18945  regress_loss -> 12.44806\n"
     ]
    }
   ],
   "source": [
    "# Instanciate the network and define the optimizer\n",
    "num_channels=3\n",
    "net = Net(n_feature = 1152, n_hidden = 256, n_output = 5, n_c = 3)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr = learning_rate)\n",
    "if(X_train.shape[1]!=num_channels): #dim1==channel\n",
    "    X_train = X_train.transpose((0,3,1,2))\n",
    "n_batch = X_train.shape[0]//batch_size\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    for batch in range(n_batch):\n",
    "        batch_X = X_train[batch*batch_size:min((batch+1)*batch_size, X_train.shape[0])]\n",
    "        batch_y = Y_train[batch*batch_size:min((batch+1)*batch_size, X_train.shape[0])]\n",
    "        out_box, out_logit = net(torch.tensor(batch_X, dtype=torch.float32))\n",
    "        \n",
    "        mask_arr = np.argwhere(batch_y[:,-1]==1).reshape((-1,))\n",
    "        regression_loss = regression_criterion(out_box[mask_arr], torch.tensor(batch_y[mask_arr,:-1], dtype=torch.float32))\n",
    "        classification_loss = classification_criterion(out_logit, torch.tensor(batch_y[:,-1:], dtype=torch.float32))\n",
    "        \n",
    "        # Compose the 2 loss functions using the weight gamma (1 line)\n",
    "        loss = gamma*(regression_loss)+(1-gamma)*classification_loss \n",
    "        \n",
    "        optimizer.zero_grad()   # clear gradients for next train\n",
    "        loss.backward()         # backpropagation, compute gradients\n",
    "        optimizer.step()        # apply gradients\n",
    "    \n",
    "    print('epoch: {}  Total loss -> {:.5f}   classif_loss -> {:.5f}  regress_loss -> {:.5f}'\n",
    "          .format(epoch, loss.item(), classification_loss.item(), regression_loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(pred_class, pred_bboxes, test_bboxes):\n",
    "    # Calculate the mean IOU (overlap) between the predicted and expected bounding boxes on the test dataset. \n",
    "    summed_IOU = 0.\n",
    "    l =0\n",
    "    for pred_bbox, test_bbox in zip(pred_bboxes.reshape(-1, 4), test_bboxes.reshape(-1, 5)):\n",
    "        if(test_bbox[4]==1): # the ones that have black boxes\n",
    "            summed_IOU += calculate_IOU(pred_bbox, test_bbox)\n",
    "            l+=1\n",
    "    mean_IOU = summed_IOU / l\n",
    "    print(\"mean IOU: \", mean_IOU)\n",
    "\n",
    "    # classification accuracy\n",
    "    print(\"classification acc: \", np.mean(test_bboxes[:,4:]==pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean IOU:  0.6023324235574279\n",
      "classification acc:  0.9061205398904183\n"
     ]
    }
   ],
   "source": [
    "if(X_train.shape[1]!=num_channels):\n",
    "    X_train = train_X.transpose((0,3,1,2))\n",
    "# Predict bounding boxes on the train images.\n",
    "with torch.no_grad():\n",
    "    pred_y_train_box, pred_y_train_logit = net.forward(torch.tensor(X_train, dtype=torch.float32))\n",
    "    pred_y_train_box, pred_y_train_logit = pred_y_train_box.numpy(), pred_y_train_logit.numpy()\n",
    "    pred_y_train_label = pred_y_train_logit>0.5\n",
    "    pred_bboxes_train = pred_y_train_box\n",
    "    pred_bboxes_train = pred_bboxes_train.reshape(len(pred_bboxes_train), 1, -1)\n",
    "    pred_bboxes_train.shape\n",
    "\n",
    "calculate_accuracy(pred_y_train_label, pred_bboxes_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean IOU:  0.6020962485741526\n",
      "classification acc:  0.8530927835051546\n"
     ]
    }
   ],
   "source": [
    "if(X_test.shape[1]!=num_channels):\n",
    "    X_test = X_test.transpose((0,3,1,2))\n",
    "# Predict bounding boxes on the train images.\n",
    "with torch.no_grad():\n",
    "    pred_y_test_box, pred_y_test_logit = net.forward(torch.tensor(X_test, dtype=torch.float32))\n",
    "    pred_y_test_box, pred_y_test_logit = pred_y_test_box.numpy(), pred_y_test_logit.numpy()\n",
    "    pred_y_test_label = pred_y_test_logit>0.5\n",
    "    pred_bboxes_test = pred_y_test_box\n",
    "    pred_bboxes_test = pred_bboxes_test.reshape(len(pred_bboxes_test), 1, -1)\n",
    "    pred_bboxes_test.shape\n",
    "\n",
    "calculate_accuracy(pred_y_test_label, pred_bboxes_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean IOU:  0.586792329312264\n",
      "classification acc:  0.9252761533463287\n"
     ]
    }
   ],
   "source": [
    "if(X_val.shape[1]!=num_channels):\n",
    "    X_val = X_val.transpose((0,3,1,2))\n",
    "# Predict bounding boxes on the train images.\n",
    "with torch.no_grad():\n",
    "    pred_y_val_box, pred_y_val_logit = net.forward(torch.tensor(X_val, dtype=torch.float32))\n",
    "    pred_y_val_box, pred_y_val_logit = pred_y_val_box.numpy(), pred_y_val_logit.numpy()\n",
    "    pred_y_val_label = pred_y_val_logit>0.5\n",
    "    pred_bboxes_val = pred_y_val_box\n",
    "    pred_bboxes_val = pred_bboxes_val.reshape(len(pred_bboxes_val), 1, -1)\n",
    "    pred_bboxes_val.shape\n",
    "\n",
    "calculate_accuracy(pred_y_val_label, pred_bboxes_val, Y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Finding varroas by segmentation\n",
    "Add your implementation for ''**detect_by_segmentation**'' function. Please make sure the input and output follows the mentioned format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_by_segmentation(img):\n",
    "    '''\n",
    "    Input: One single image\n",
    "    Output: A numpy array containing coordonates of all detected varroas, with the following format: \n",
    "            [[x_1, y_1, w_1, h_2], [x_2, y_2, w_1, h_2], ..., [x_n, y_n, w_n, h_n]] \n",
    "            where ''n'' is the number of detected varroas.\n",
    "    '''\n",
    "\n",
    "    #Your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add your implementation. Report the Precision, Recall and F1-score, by using all 50 images of the test-set, and considering 0.3 as the IoU threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Implement your first detector\n",
    "\n",
    "Write your function(s) for the second part. Feel free to change the name of the function and add your additional functions, but please make sure their input and output follows the mentioned format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_by_method_1(img):\n",
    "    '''\n",
    "    Input: One single image\n",
    "    Output: A numpy array containing coordonates of all detected varroas, with the following format: \n",
    "            [[x_1, y_1, w_1, h_2], [x_2, y_2, w_1, h_2], ..., [x_n, y_n, w_n, h_n]] \n",
    "            where ''n'' is the number of detected varroas.\n",
    "    '''\n",
    "\n",
    "    #Your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add your implementation. Report the Precision, Recall and F1-score, by using all 50 images of the test-set, and considering 0.3 as the IoU threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Using MLP and CNNs\n",
    "\n",
    "Add your implementation for the thrid part. Feel free to add your desirable functions, but please make sure you have proper functions for the final detection, where their input and output follows the same format as the previous parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "You can generate a json submission file by using the function ''**generate_pred_json**''. This prediction file can be uploaded online for evaluation (Please refer to section 3 of the project description for more details)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "\n",
    "def generate_pred_json(data, tag='baseline'):\n",
    "    '''\n",
    "    Input\n",
    "    - data: Is a dictionary d, such that:\n",
    "          d = { \n",
    "              \"ID_1\": [], \n",
    "              \"ID_2\": [[x_21, y_21, w_21, h_21], [x_22, y_22, w_22, h_22]], \n",
    "              ... \n",
    "              \"ID_i\": [[x_i1, y_i1, w_i1, h_i1], ..., [x_iJ, y_iJ, w_iJ, h_iJ]],\n",
    "              ... \n",
    "              \"ID_N\": [[x_N1, y_N1, w_N1, h_N1]],\n",
    "          }\n",
    "          where ID is the string id of the image (e.i. 5a05e86fa07d56baef59b1cb_32.00px_1) and the value the Kx4 \n",
    "          array of intergers for the K predicted bounding boxes (e.g. [[170, 120, 15, 15]])\n",
    "    - tag: (optional) string that will be added to the name of the json file.\n",
    "    Output\n",
    "      Create a json file, \"prediction_[tag].json\", conatining the prediction to EvalAI format.\n",
    "    '''\n",
    "    unvalid_key = []\n",
    "    _data = data.copy()\n",
    "    for key, value in _data.items():\n",
    "        try:\n",
    "            # Try to convert to numpy array and cast as closest int\n",
    "            print(key)\n",
    "            v = np.around(np.array(value)).astype(int)\n",
    "            # Check is it is a 2d array with 4 columns (x,y,w,h)\n",
    "            if v.ndim != 2 or v.shape[1] != 4:\n",
    "                unvalid_key.append(key)\n",
    "            # Id must be a string\n",
    "            if not isinstance(key, str):\n",
    "                unvalid_key.append(key)\n",
    "            _data[key] = v.tolist()\n",
    "        # Deal with not consistant array size and empty predictions\n",
    "        except (ValueError, TypeError):\n",
    "            unvalid_key.append(key)\n",
    "    # Remove unvalid key from dictionnary\n",
    "    for key in unvalid_key: del _data[key]\n",
    "    \n",
    "    with open('prediction_{}.json'.format(tag), 'w') as outfile:\n",
    "        json.dump(_data, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
