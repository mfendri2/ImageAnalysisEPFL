{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [IAPR 2019:][iapr2019] Special project\n",
    "\n",
    "**Group members:**\n",
    "    1- first name and last name,\n",
    "    2- first name and last name,\n",
    "    3- first name and last name\n",
    "\n",
    "**Due date:** 30.05.2019\n",
    "\n",
    "[iapr2019]: https://github.com/LTS5/iapr-2019\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "Please find the description of this special project via [this link].\n",
    "\n",
    "[this link]: https://github.com/LTS5/iapr-2019/blob/master/project/special_project_description.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hedi Fendri\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "import warnings\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import decomposition\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve,auc,roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import  average_precision_score\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import os\n",
    "from PIL import Image, ImageDraw\n",
    "import math\n",
    "import cv2 \n",
    "import xml.etree.ElementTree as ET\n",
    "from skimage import feature\n",
    "from skimage import transform\n",
    "from skimage import measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 956,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train image size 800 , test image size 50, validation image size 150\n"
     ]
    }
   ],
   "source": [
    "src_path_train = './project-data/images/train/'\n",
    "xml_path_train=\"./project-data/annotations/train/\"\n",
    "prepared_data_path=\"./project-data/images/train/prepared_data/\"\n",
    "fp_data_path=\"./project-data/images/train/false_positive/\"\n",
    "img_list_dir = os.listdir(src_path_train)\n",
    "img_list = [names for names in img_list_dir if names.endswith(\".jpg\")]\n",
    "img_list_size = len(img_list)\n",
    "\n",
    "src_path_test = './project-data/images/test/'\n",
    "xml_path_test=\"./project-data/annotations/test/\"\n",
    "prepared_data_path_test=\"./project-data/images/test/prepared_data/\"\n",
    "img_list_dir_test = os.listdir(src_path_test)\n",
    "img_list_test = [names for names in img_list_dir_test  if names.endswith(\".jpg\")]\n",
    "img_list_size_test = len(img_list_test)\n",
    "\n",
    "src_path_validation = './project-data/images/validation/'\n",
    "xml_path_validation=\"./project-data/annotations/validation/\"\n",
    "prepared_data_path_validation=\"./project-data/images/validation/prepared_data/\"\n",
    "img_list_dir_validation = os.listdir(src_path_validation)\n",
    "img_list_validation = [names for names in img_list_dir_validation  if names.endswith(\".jpg\")]\n",
    "img_list_size_validation = len(img_list_validation)\n",
    "print(\"train image size {} , test image size {}, validation image size {}\".format(img_list_size,img_list_size_test,img_list_size_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_file(filename):\n",
    "    \"\"\" Parse a PASCAL VOC xml file \"\"\"\n",
    "    tree = ET.parse(filename)\n",
    "    objects = []\n",
    "    for obj in tree.findall('object'):\n",
    "        obj_struct = {}\n",
    "        obj_struct['name'] = obj.find('name').text\n",
    "        bbox = obj.find('bndbox')\n",
    "        obj_struct['bbox'] = [int(float(bbox.find('xmin').text)),\n",
    "                              int(float(bbox.find('ymin').text)),\n",
    "                              int(float(bbox.find('xmax').text))-int(float(bbox.find('xmin').text)),\n",
    "                              int(float(bbox.find('ymax').text))-int(float(bbox.find('ymin').text))]\n",
    "        objects.append(obj_struct)\n",
    "    return objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_xmls = [parse_file(os.path.join(xml_path_train, name[:-4]) + '.xml') for name in img_list]\n",
    "annotations_xmls_test=[parse_file(os.path.join(xml_path_test, name[:-4]) + '.xml') for name in img_list_test]\n",
    "annotations_xmls_validation=[parse_file(os.path.join(xml_path_validation, name[:-4]) + '.xml') for name in img_list_validation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_IOU(bbox1, bbox2):\n",
    "    #Calculate overlap between two bounding boxes [x, y, w, h] as the area of intersection over the area of unity\n",
    "    \n",
    "    #determine the (x, y)-coordinates of the intersection rectangle\n",
    "    x1, y1, w1, h1 = bbox1[0], bbox1[1], bbox1[2], bbox1[3]\n",
    "    x2, y2, w2, h2 = bbox2[0], bbox2[1], bbox2[2], bbox2[3]\n",
    "    \n",
    "    \n",
    "    xA = max(x1, x2)\n",
    "    yA = max(y1, y2)\n",
    "    xB = min(x1+w1, x2+w2)\n",
    "    yB = min(y1+h1, y2+h2)\n",
    "    # compute the area of intersection rectangle\n",
    "    interArea = max(0, xB - xA ) * max(0, yB - yA )\n",
    "    \n",
    "    # compute the area of both the prediction and ground-truth\n",
    "    boxAArea = (w1 ) * (h1 )\n",
    "    boxBArea = (w2 ) * (h2 )\n",
    "\n",
    "    # compute the intersection over union by taking the intersection\n",
    "    # area and dividing it by the sum of prediction + ground-truth\n",
    "    # areas - the interesection area\n",
    "    iou = interArea / float(boxAArea + boxBArea - interArea)\n",
    "\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_and_label(prepared_data_path,img,img_name,annotations): \n",
    "    #Mirror padding\n",
    "    w,h,d = img.shape \n",
    "    w_i=int(w/32)+1\n",
    "    h_i=int(h/32)+1\n",
    "    new_w=w_i*32\n",
    "    new_h=h_i*32\n",
    "    count=0\n",
    "    new_img=img\n",
    "    l=0\n",
    "    for i in range(w_i): \n",
    "        for j in range(h_i): \n",
    "            count+=1 \n",
    "            name=img_name+\"_\"+str(count)\n",
    "            sub_img=new_img[0:64,0:64,:]\n",
    "            label=0\n",
    "            for box in annotations:\n",
    "                if (box[0]>=i*32  and box[0]< i*32+64 and box[1]>=j*32 and  box[1]< j*32+64) :\n",
    "                    if ( box[0]+box[2]<i*32+64 and box[1]+box[3]<j*32+64):\n",
    "                        l=l+1\n",
    "                        label=1\n",
    "                \"\"\"\"\n",
    "                iou=calculate_IOU(box,[i*32,j*32,64,64])\n",
    "                if (iou>0.5): \n",
    "                    label=1 \n",
    "                    j=j+1\n",
    "                    break\n",
    "                \"\"\"\n",
    "            name+=\"_\"+str(label)\n",
    "            im=Image.fromarray(sub_img)\n",
    "            b, g, r = im.split()\n",
    "            im= Image.merge(\"RGB\", (r, g, b))\n",
    "            im.save(prepared_data_path+name+\".jpg\")         \n",
    "            new_img=np.roll(new_img,-32,axis=1)\n",
    "        new_img=np.roll(new_img,-32,axis=0)\n",
    "    return l "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train max box size [56] , test max box size [52], validation max box size [52]\n"
     ]
    }
   ],
   "source": [
    "ground_truth_1=[]\n",
    "for j in range(len(annotations_xmls)):\n",
    "    for i in range(len(annotations_xmls[j])): \n",
    "        ground_truth_1.append(annotations_xmls[j][i]['bbox'][2:3])\n",
    "max_box_size=max(ground_truth_1)\n",
    "ground_truth_1=[]\n",
    "\n",
    "for j in range(len(annotations_xmls_test)):\n",
    "    for i in range(len(annotations_xmls_test[j])): \n",
    "        ground_truth_1.append(annotations_xmls_test[j][i]['bbox'][2:3])\n",
    "max_box_size_test=max(ground_truth_1)\n",
    "\n",
    "for j in range(len(annotations_xmls_validation)):\n",
    "    for i in range(len(annotations_xmls_validation[j])): \n",
    "        ground_truth_1.append(annotations_xmls_validation[j][i]['bbox'][2:3])\n",
    "max_box_size_validation=max(ground_truth_1)\n",
    "print(\"train max box size {} , test max box size {}, validation max box size {}\".format(max_box_size,max_box_size_test,max_box_size_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def split_and_label_v2(prepared_data_path,max_box_size,img,img_name,annotations): \n",
    "    count=0\n",
    "    width,height=img.shape[0],img.shape[1]\n",
    "    bbox=[]\n",
    "    for box in annotations: \n",
    "        name=img_name+\"_\"+str(count)+\"_1\"\n",
    "\n",
    "        xmin,ymin,w,h=box[0],box[1],box[2],box[3] \n",
    "        max_size=int(max_box_size[0]/2)\n",
    "        new_img_=img[max(0,ymin-10):min(ymin+max_size+10,width),max(0,xmin-10):min(xmin+max_size+10,height),:]\n",
    "        im=Image.fromarray(new_img_)\n",
    "        bbox.append([10,10,box[2],box[3],1])\n",
    "        b, g, r = im.split()\n",
    "        im= Image.merge(\"RGB\", (r, g, b))\n",
    "        im.save(prepared_data_path+name+\".jpg\") \n",
    "        name=img_name+\"_\"+str(count)+\"_0\"\n",
    "        if (xmin-56)>0 and (ymin-56)>0:\n",
    "            x1 = random.randint(0, xmin-56)\n",
    "            y1 = random.randint(0, ymin-56)\n",
    "        else :\n",
    "            x1 = random.randint(0, min(xmin+56,height))\n",
    "            y1 = random.randint(0, min(ymin+56,width))\n",
    "        new_img=img[y1:min(y1+48,width),x1:min(height,x1+48),:]\n",
    "        bbox.append([0,0,0,0,0])\n",
    "        im=Image.fromarray(new_img)\n",
    "        b, g, r = im.split()\n",
    "        im= Image.merge(\"RGB\", (r, g, b))\n",
    "        im.save(prepared_data_path+name+\".jpg\") \n",
    "        count+=1\n",
    "    return bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(img_list,src_path,max_box_size,prepared_data_path,annotations_xmls):\n",
    "    bbox=[]\n",
    "    for j in range(len(img_list)):\n",
    "        name=img_list[j]\n",
    "        img = cv2.imread(src_path+name)\n",
    "        ground_truth_1=[]\n",
    "        for i in range(len(annotations_xmls[j])): \n",
    "            ground_truth_1.append(annotations_xmls[j][i]['bbox'])\n",
    "        ground_truth_1\n",
    "        bbox.append(split_and_label_v2(prepared_data_path,max_box_size,img,name[:-4],ground_truth_1))\n",
    "    return bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "print(len(annotations_xmls_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox=make_dataset(img_list,src_path_train,max_box_size,prepared_data_path,annotations_xmls)\n",
    "bbox_test=make_dataset(img_list_test,src_path_test,max_box_size_test,prepared_data_path_test,annotations_xmls_test)\n",
    "bbox_validation=make_dataset(img_list_validation,src_path_validation,max_box_size_validation,prepared_data_path_validation,annotations_xmls_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOR TRAINING\n",
      "number of images with label =1 (varroas) is  7483\n",
      "number of images with label =0 (non varroas) is  7483\n",
      "Total number of files =  14966\n",
      "FOR TESTING\n",
      "number of images with label =1 (varroas) is  582\n",
      "number of images with label =0 (non varroas) is  582\n",
      "Total number of files =  1164\n",
      "FOR VALIDATION\n",
      "number of images with label =1 (varroas) is  1539\n",
      "number of images with label =0 (non varroas) is  1539\n",
      "Total number of files =  3078\n"
     ]
    }
   ],
   "source": [
    "img_list_dir_prep = os.listdir(prepared_data_path)\n",
    "number_label_non_varroa_train=0\n",
    "number_label_varroa_train=0\n",
    "for prep_name in img_list_dir_prep: \n",
    "    if prep_name.endswith('_1.jpg'):\n",
    "        number_label_varroa_train+=1\n",
    "    if prep_name.endswith('_0.jpg'):\n",
    "        number_label_non_varroa_train+=1\n",
    "print(\"FOR TRAINING\")\n",
    "print(\"number of images with label =1 (varroas) is \",number_label_non_varroa_train)\n",
    "print(\"number of images with label =0 (non varroas) is \",number_label_varroa_train)\n",
    "print(\"Total number of files = \",number_label_varroa_train+number_label_non_varroa_train)    \n",
    "\n",
    "img_list_dir_prep_test = os.listdir(prepared_data_path_test)\n",
    "number_label_non_varroa_test=0\n",
    "number_label_varroa_test=0\n",
    "for prep_name in img_list_dir_prep_test: \n",
    "    if prep_name.endswith('_1.jpg'):\n",
    "        number_label_varroa_test+=1\n",
    "    if prep_name.endswith('_0.jpg'):\n",
    "        number_label_non_varroa_test+=1\n",
    "print(\"FOR TESTING\")\n",
    "print(\"number of images with label =1 (varroas) is \",number_label_non_varroa_test)\n",
    "print(\"number of images with label =0 (non varroas) is \",number_label_varroa_test)\n",
    "print(\"Total number of files = \",number_label_varroa_test+number_label_non_varroa_test)\n",
    "\n",
    "img_list_dir_prep_validation = os.listdir(prepared_data_path_validation)\n",
    "number_label_non_varroa_val=0\n",
    "number_label_varroa_val=0\n",
    "for prep_name in img_list_dir_prep_validation: \n",
    "    if prep_name.endswith('_1.jpg'):\n",
    "        number_label_varroa_val+=1\n",
    "    if prep_name.endswith('_0.jpg'):\n",
    "        number_label_non_varroa_val+=1\n",
    "print(\"FOR VALIDATION\")\n",
    "print(\"number of images with label =1 (varroas) is \",number_label_non_varroa_val)\n",
    "print(\"number of images with label =0 (non varroas) is \",number_label_varroa_val)\n",
    "print(\"Total number of files = \",number_label_varroa_val+number_label_non_varroa_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize(img_list_dir_prep,prepared_data_path):\n",
    "    img_list_prep = [names for names in img_list_dir_prep if names.endswith(\".jpg\")]\n",
    "    sizes = [Image.open(prepared_data_path+f, 'r').size for f in img_list_prep]\n",
    "    max_width,max_height=max(sizes)\n",
    "    for item in img_list_dir_prep:\n",
    "        if os.path.isfile(prepared_data_path+item):\n",
    "            im = Image.open(prepared_data_path+item)\n",
    "            f, e = os.path.splitext(prepared_data_path+item)\n",
    "            imResize = im.resize((48,48), Image.ANTIALIAS)\n",
    "            imResize.save(f + '.jpg', 'JPEG', quality=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize(img_list_dir_prep,prepared_data_path)\n",
    "resize(img_list_dir_prep_test,prepared_data_path_test)\n",
    "resize(img_list_dir_prep_validation,prepared_data_path_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list_prep_train = [names for names in img_list_dir_prep if names.endswith(\".jpg\")]\n",
    "img_list_prep_test = [names for names in img_list_dir_prep_test if names.endswith(\".jpg\")]\n",
    "img_list_prep_validation = [names for names in img_list_dir_prep_validation if names.endswith(\".jpg\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_imgs_train=number_label_varroa_train+number_label_non_varroa_train\n",
    "num_imgs_test=number_label_varroa_test+number_label_non_varroa_test\n",
    "num_imgs_validation=number_label_varroa_val+number_label_non_varroa_val\n",
    "\n",
    "X_train=np.zeros((num_imgs_train,48,48,3))\n",
    "for i in range(len(img_list_prep_train)):\n",
    "    name=img_list_prep_train[i]\n",
    "    img = cv2.imread(prepared_data_path+name)\n",
    "    X_train[i,:,:,:]=img\n",
    "\n",
    "X_test=np.zeros((num_imgs_test,48,48,3))\n",
    "for i in range(len(img_list_prep_test)):\n",
    "    name=img_list_prep_test[i]\n",
    "    img = cv2.imread(prepared_data_path_test+name)\n",
    "    X_test[i,:,:,:]=img\n",
    "\n",
    "X_val=np.zeros((num_imgs_validation,48,48,3))\n",
    "for i in range(len(img_list_prep_validation)):\n",
    "    name=img_list_prep_validation[i]\n",
    "    img = cv2.imread(prepared_data_path_validation+name)\n",
    "    X_val[i,:,:,:]=img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14966, 48, 48, 3)\n",
      "(1164, 48, 48, 3)\n",
      "(3078, 48, 48, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "bbox_train_=np.zeros((X_train.shape[0],5))\n",
    "for image_box in bbox: \n",
    "    for box in image_box:\n",
    "        bbox_train_[count,0]=box[0]\n",
    "        bbox_train_[count,1]=box[1]\n",
    "        bbox_train_[count,2]=box[2]\n",
    "        bbox_train_[count,3]=box[3]\n",
    "        bbox_train_[count,4]=box[4]\n",
    "        count+=1  \n",
    "\n",
    "count=0\n",
    "bbox_test_=np.zeros((X_test.shape[0],5))\n",
    "for image_box in bbox_test: \n",
    "    for box in image_box:\n",
    "        bbox_test_[count,0]=box[0]\n",
    "        bbox_test_[count,1]=box[1]\n",
    "        bbox_test_[count,2]=box[2]\n",
    "        bbox_test_[count,3]=box[3]\n",
    "        bbox_test_[count,4]=box[4]\n",
    "        count+=1  \n",
    "\n",
    "count=0\n",
    "bbox_validation_=np.zeros((X_val.shape[0],5))\n",
    "for image_box in bbox_validation: \n",
    "    for box in image_box:\n",
    "        bbox_validation_[count,0]=box[0]\n",
    "        bbox_validation_[count,1]=box[1]\n",
    "        bbox_validation_[count,2]=box[2]\n",
    "        bbox_validation_[count,3]=box[3]\n",
    "        bbox_validation_[count,4]=box[4]\n",
    "        count+=1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 858,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train=bbox_train_\n",
    "Y_test=bbox_test_\n",
    "Y_val=bbox_validation_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 878,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "num_epoch = 20\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[-2.84827786e-12  8.20058727e-13 -7.27218541e-13]]]] [[[[1. 1. 1.]]]]\n",
      "[[[[159.62844202 154.83111845 150.52723114]]]] [[[[62.44289658 53.83234143 44.50817755]]]]\n",
      "[[[[134.62986441 134.33773128 134.0592995 ]]]] [[[[57.06324345 51.75719531 43.16581642]]]]\n"
     ]
    }
   ],
   "source": [
    "imgs_mean_train = np.mean(X_train,axis=(0,1,2)).reshape((1,1,1,-1))\n",
    "imgs_std_train = np.std(X_train,axis=(0,1,2)).reshape((1,1,1,-1))\n",
    "print(imgs_mean_train,imgs_std_train)\n",
    "\n",
    "imgs_mean_test = np.mean(X_test,axis=(0,1,2)).reshape((1,1,1,-1))\n",
    "imgs_std_test = np.std(X_test,axis=(0,1,2)).reshape((1,1,1,-1))\n",
    "print(imgs_mean_test,imgs_std_test)\n",
    "\n",
    "imgs_mean_val = np.mean(X_val,axis=(0,1,2)).reshape((1,1,1,-1))\n",
    "imgs_std_val = np.std(X_val,axis=(0,1,2)).reshape((1,1,1,-1))\n",
    "print(imgs_mean_val,imgs_std_val)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14966, 48, 48, 3) 1.8373571799704925e-12 1.0000000000002423\n",
      "(1164, 48, 48, 3) 1.7571112779959046e-16 0.9999999999991176\n",
      "(3078, 48, 48, 3) -7.279451269864641e-17 1.0000000000011238\n"
     ]
    }
   ],
   "source": [
    "X_train = (X_train - imgs_mean_train) / imgs_std_train #.reshape(num_imgs, -1)\n",
    "print(X_train.shape, np.mean(X_train), np.std(X_train))\n",
    "\n",
    "X_test = (X_test - imgs_mean_test) / imgs_std_test #.reshape(num_imgs, -1)\n",
    "print(X_test.shape, np.mean(X_test), np.std(X_test))\n",
    "\n",
    "X_val = (X_val - imgs_mean_val) / imgs_std_val #.reshape(num_imgs, -1)\n",
    "print(X_val.shape, np.mean(X_val), np.std(X_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 860,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14966, 5) 0.2644112766715667 0.3443376734163612\n",
      "(1164, 5) 0.2775916380297824 0.35793506091194716\n",
      "(3078, 5) 0.26405945419103316 0.3437247903780434\n"
     ]
    }
   ],
   "source": [
    "Y_train = bbox_train_.reshape(num_imgs_train, -1).copy()\n",
    "Y_train[:,0:4] = Y_train[:,0:4]/48\n",
    "print(Y_train.shape, np.mean(Y_train), np.std(Y_train))\n",
    "\n",
    "Y_test = bbox_test_.reshape(num_imgs_test, -1).copy()\n",
    "Y_test[:,0:4] = Y_test[:,0:4]/48\n",
    "print(Y_test.shape, np.mean(Y_test), np.std(Y_test))\n",
    "\n",
    "Y_val = bbox_validation_.reshape(num_imgs_validation, -1).copy()\n",
    "Y_val[:,0:4] = Y_val[:,0:4]/48\n",
    "print(Y_val.shape, np.mean(Y_val), np.std(Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (hidden): Linear(in_features=1152, out_features=256, bias=True)\n",
      "  (box): Linear(in_features=256, out_features=4, bias=True)\n",
      "  (logit): Linear(in_features=256, out_features=1, bias=True)\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(3, 8, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(8, 16, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (conv3): Sequential(\n",
      "    (0): Conv2d(16, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# define network architecture\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, n_feature, n_hidden, n_output, n_c):\n",
    "        super(Net, self).__init__()\n",
    "        self.hidden = torch.nn.Linear(n_feature, n_hidden)   # hidden layer\n",
    "        self.box = torch.nn.Linear(n_hidden, n_output-1)   # output layer\n",
    "        self.logit = torch.nn.Linear(n_hidden, 1)\n",
    "        \n",
    "        self.conv1 = torch.nn.Sequential(         # \n",
    "            torch.nn.Conv2d(\n",
    "                in_channels = n_c,            # input height\n",
    "                out_channels = 8,             # n_filters\n",
    "                kernel_size = 2,              # filter size\n",
    "                stride = 2,                   # filter movement/step\n",
    "                padding = 0,                  \n",
    "            ),                              \n",
    "            torch.nn.ReLU(),                      # activation\n",
    "            #torch.nn.MaxPool2d(kernel_size = 2),    \n",
    "        )\n",
    "        self.conv2 = torch.nn.Sequential(       \n",
    "            torch.nn.Conv2d(in_channels = 8, \n",
    "                            out_channels = 16, \n",
    "                            kernel_size = 2, \n",
    "                            stride = 2, \n",
    "                            padding = 0),      \n",
    "            torch.nn.ReLU(),                      # activation\n",
    "            #torch.nn.MaxPool2d(2),                \n",
    "        )\n",
    "        \n",
    "        self.conv3 = torch.nn.Sequential(       \n",
    "            torch.nn.Conv2d(in_channels = 16, \n",
    "                            out_channels = 8, \n",
    "                            kernel_size = 1, \n",
    "                            stride = 1, \n",
    "                            padding = 0),      \n",
    "            torch.nn.ReLU(),                      # activation\n",
    "            #torch.nn.MaxPool2d(2),                \n",
    "        )\n",
    "    def forward(self, x):\n",
    "        feat = self.conv1(x)\n",
    "        feat = self.conv2(feat)\n",
    "       \n",
    "        feat = self.conv3(feat)\n",
    "        feat = feat.view(feat.size(0), -1)\n",
    "        \n",
    "        x2 = F.relu(self.hidden(feat))      # activation function for hidden layer\n",
    "       \n",
    "        out_box = F.relu(self.box(x2))            # linear output\n",
    "        out_logit = torch.sigmoid(self.logit(x2))\n",
    "        \n",
    "        return out_box, out_logit\n",
    "      \n",
    "net = Net(n_feature = 1152, n_hidden = 256, n_output = 5, n_c = 3)     # define the network\n",
    "print(net)  # net architecture\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 894,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_criterion =  torch.nn.MSELoss()\n",
    "classification_criterion =  torch.nn.BCELoss()# Hint: Consider that we only one class to predict\n",
    "gamma =0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 895,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0  Total loss -> 0.03543   classif_loss -> 0.03815  regress_loss -> 0.01096\n",
      "epoch: 1  Total loss -> 0.02778   classif_loss -> 0.02989  regress_loss -> 0.00881\n",
      "epoch: 2  Total loss -> 0.02491   classif_loss -> 0.02681  regress_loss -> 0.00783\n",
      "epoch: 3  Total loss -> 0.02537   classif_loss -> 0.02737  regress_loss -> 0.00739\n",
      "epoch: 4  Total loss -> 0.02336   classif_loss -> 0.02511  regress_loss -> 0.00758\n",
      "epoch: 5  Total loss -> 0.02183   classif_loss -> 0.02338  regress_loss -> 0.00788\n",
      "epoch: 6  Total loss -> 0.02160   classif_loss -> 0.02311  regress_loss -> 0.00804\n",
      "epoch: 7  Total loss -> 0.02104   classif_loss -> 0.02256  regress_loss -> 0.00743\n",
      "epoch: 8  Total loss -> 0.01981   classif_loss -> 0.02121  regress_loss -> 0.00720\n",
      "epoch: 9  Total loss -> 0.01968   classif_loss -> 0.02104  regress_loss -> 0.00739\n",
      "epoch: 10  Total loss -> 0.01912   classif_loss -> 0.02035  regress_loss -> 0.00801\n",
      "epoch: 11  Total loss -> 0.01772   classif_loss -> 0.01880  regress_loss -> 0.00802\n",
      "epoch: 12  Total loss -> 0.01749   classif_loss -> 0.01825  regress_loss -> 0.01065\n",
      "epoch: 13  Total loss -> 0.01763   classif_loss -> 0.01855  regress_loss -> 0.00940\n",
      "epoch: 14  Total loss -> 0.01764   classif_loss -> 0.01855  regress_loss -> 0.00937\n",
      "epoch: 15  Total loss -> 0.01754   classif_loss -> 0.01840  regress_loss -> 0.00978\n",
      "epoch: 16  Total loss -> 0.01669   classif_loss -> 0.01741  regress_loss -> 0.01021\n",
      "epoch: 17  Total loss -> 0.01573   classif_loss -> 0.01647  regress_loss -> 0.00906\n",
      "epoch: 18  Total loss -> 0.01504   classif_loss -> 0.01535  regress_loss -> 0.01225\n",
      "epoch: 19  Total loss -> 0.01573   classif_loss -> 0.01639  regress_loss -> 0.00975\n"
     ]
    }
   ],
   "source": [
    "# Instanciate the network and define the optimizer\n",
    "num_channels=3\n",
    "net = Net(n_feature = 1152, n_hidden = 256, n_output = 5, n_c = 3)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr = learning_rate)\n",
    "if(X_train.shape[1]!=num_channels): #dim1==channel\n",
    "    X_train = X_train.transpose((0,3,1,2))\n",
    "n_batch = X_train.shape[0]//batch_size\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    for batch in range(n_batch):\n",
    "        batch_X = X_train[batch*batch_size:min((batch+1)*batch_size, X_train.shape[0])]\n",
    "        batch_y = Y_train[batch*batch_size:min((batch+1)*batch_size, X_train.shape[0])]\n",
    "        out_box, out_logit = net(torch.tensor(batch_X, dtype=torch.float32))\n",
    "        \n",
    "        mask_arr = np.argwhere(batch_y[:,-1]==1).reshape((-1,))\n",
    "        regression_loss = regression_criterion(out_box[mask_arr], torch.tensor(batch_y[mask_arr,:-1], dtype=torch.float32))\n",
    "        classification_loss = classification_criterion(out_logit, torch.tensor(batch_y[:,-1:], dtype=torch.float32))\n",
    "        \n",
    "        # Compose the 2 loss functions using the weight gamma (1 line)\n",
    "        loss = gamma*(regression_loss)+(1-gamma)*classification_loss \n",
    "        \n",
    "        optimizer.zero_grad()   # clear gradients for next train\n",
    "        loss.backward()         # backpropagation, compute gradients\n",
    "        optimizer.step()        # apply gradients\n",
    "    \n",
    "    print('epoch: {}  Total loss -> {:.5f}   classif_loss -> {:.5f}  regress_loss -> {:.5f}'\n",
    "          .format(epoch, loss.item(), classification_loss.item(), regression_loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 896,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(pred_class, pred_bboxes, test_bboxes):\n",
    "    # Calculate the mean IOU (overlap) between the predicted and expected bounding boxes on the test dataset. \n",
    "    summed_IOU = 0.\n",
    "    l =0\n",
    "    for pred_bbox, test_bbox in zip(pred_bboxes.reshape(-1, 4), test_bboxes.reshape(-1, 5)):\n",
    "        if(test_bbox[4]==1): # the ones that have black boxes\n",
    "            summed_IOU += calculate_IOU(pred_bbox, test_bbox)\n",
    "            l+=1\n",
    "    mean_IOU = summed_IOU / l\n",
    "    print(\"mean IOU: \", mean_IOU)\n",
    "\n",
    "    # classification accuracy\n",
    "    print(\"classification acc: \", np.mean(test_bboxes[:,4:]==pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 897,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean IOU:  0.4989607892207596\n",
      "classification acc:  0.961780034745423\n"
     ]
    }
   ],
   "source": [
    "if(X_train.shape[1]!=num_channels):\n",
    "    X_train = train_X.transpose((0,3,1,2))\n",
    "# Predict bounding boxes on the train images.\n",
    "with torch.no_grad():\n",
    "    pred_y_train_box, pred_y_train_logit = net.forward(torch.tensor(X_train, dtype=torch.float32))\n",
    "    pred_y_train_box, pred_y_train_logit = pred_y_train_box.numpy(), pred_y_train_logit.numpy()\n",
    "    pred_y_train_label = pred_y_train_logit>0.5\n",
    "    pred_bboxes_train = pred_y_train_box\n",
    "    pred_bboxes_train = pred_bboxes_train.reshape(len(pred_bboxes_train), 1, -1)\n",
    "    pred_bboxes_train.shape\n",
    "\n",
    "calculate_accuracy(pred_y_train_label, pred_bboxes_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 898,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean IOU:  0.41823556097341325\n",
      "classification acc:  0.9278350515463918\n"
     ]
    }
   ],
   "source": [
    "if(X_test.shape[1]!=num_channels):\n",
    "    X_test = X_test.transpose((0,3,1,2))\n",
    "# Predict bounding boxes on the train images.\n",
    "with torch.no_grad():\n",
    "    pred_y_test_box, pred_y_test_logit = net.forward(torch.tensor(X_test, dtype=torch.float32))\n",
    "    pred_y_test_box, pred_y_test_logit = pred_y_test_box.numpy(), pred_y_test_logit.numpy()\n",
    "    pred_y_test_label = pred_y_test_logit>0.5\n",
    "    pred_bboxes_test = pred_y_test_box\n",
    "    pred_bboxes_test = pred_bboxes_test.reshape(len(pred_bboxes_test), 1, -1)\n",
    "    pred_bboxes_test.shape\n",
    "\n",
    "calculate_accuracy(pred_y_test_label, pred_bboxes_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10., 10., 35., 33., 48.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.],\n",
       "       [10., 10., 36., 38., 48.],\n",
       "       ...,\n",
       "       [ 0.,  0.,  0.,  0.,  0.],\n",
       "       [10., 10., 25., 26., 48.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test*48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[10.448693 ,  9.678261 , 23.745543 , 25.29     ]],\n",
       "\n",
       "       [[10.896969 , 10.014378 , 26.241203 , 26.493729 ]],\n",
       "\n",
       "       [[10.121657 , 10.031761 , 25.923126 , 26.480524 ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 9.8310175,  8.662792 , 20.991238 , 24.042583 ]],\n",
       "\n",
       "       [[ 9.972276 ,  9.820082 , 23.092058 , 23.900698 ]],\n",
       "\n",
       "       [[ 9.370278 , 10.164831 , 24.244097 , 23.863594 ]]], dtype=float32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_bboxes_test*48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 899,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean IOU:  0.4808673437216353\n",
      "classification acc:  0.9587394411955815\n"
     ]
    }
   ],
   "source": [
    "if(X_val.shape[1]!=num_channels):\n",
    "    X_val = X_val.transpose((0,3,1,2))\n",
    "# Predict bounding boxes on the train images.\n",
    "with torch.no_grad():\n",
    "    pred_y_val_box, pred_y_val_logit = net.forward(torch.tensor(X_val, dtype=torch.float32))\n",
    "    pred_y_val_box, pred_y_val_logit = pred_y_val_box.numpy(), pred_y_val_logit.numpy()\n",
    "    pred_y_val_label = pred_y_val_logit>0.5\n",
    "    idx=np.where(pred_y_val_label==0)\n",
    "    pred_y_val_box[idx[0],:]=[0,0,0,0]\n",
    "    pred_bboxes_val = pred_y_val_box\n",
    "    pred_bboxes_val = pred_bboxes_val.reshape(len(pred_bboxes_val), 1, -1)\n",
    "    \n",
    "\n",
    "calculate_accuracy(pred_y_val_label, pred_bboxes_val, Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 843,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[10.304321,  9.519056, 25.494823, 25.872894]],\n",
       "\n",
       "       [[ 0.      ,  0.      ,  0.      ,  0.      ]],\n",
       "\n",
       "       [[10.072835,  9.666082, 25.433384, 25.449043]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 0.      ,  0.      ,  0.      ,  0.      ]],\n",
       "\n",
       "       [[ 9.949468,  9.995354, 22.35059 , 22.923737]],\n",
       "\n",
       "       [[ 0.      ,  0.      ,  0.      ,  0.      ]]], dtype=float32)"
      ]
     },
     "execution_count": 843,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_bboxes_val*48"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Detector by manually creating feature space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the training feature space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_simple=np.zeros((len(img_list_prep_train),2))\n",
    "kernelSize=4\n",
    "kernel = np.ones((kernelSize,kernelSize))\n",
    "\n",
    "for i in range(len(img_list_prep_train)):\n",
    "    name=img_list_prep_train[i]\n",
    "    #if i==0 : #print(name)\n",
    "    img = cv2.imread(prepared_data_path+name)\n",
    "    im= cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    ret,thresh = cv2.threshold(im,100,255,cv2.THRESH_BINARY)    \n",
    "    thresh[thresh>0]=1\n",
    "    if(np.sum(thresh>0)>2100):\n",
    "        thresh=np.zeros_like(thresh)\n",
    "    image_proprieties = measure.regionprops(thresh)\n",
    "    for prop in image_proprieties: \n",
    "        X_train_simple[i,0]=np.max(prop.area)\n",
    "        X_train_simple[i,1]=np.max(prop.perimeter)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the testing feature space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_simple=np.zeros((len(img_list_prep_test),2))\n",
    "kernelSize=4\n",
    "kernel = np.ones((kernelSize,kernelSize))\n",
    "\n",
    "for i in range(len(img_list_prep_test)):\n",
    "    name=img_list_prep_test[i]\n",
    "    #if i==0 : #print(name)\n",
    "    img = cv2.imread(prepared_data_path_test+name)\n",
    "    im= cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    ret,thresh = cv2.threshold(im,100,255,cv2.THRESH_BINARY)    \n",
    "    thresh[thresh>0]=1  \n",
    "    if(np.sum(thresh>0)>2100):\n",
    "        thresh=np.zeros_like(thresh)\n",
    " \n",
    "    image_proprieties = measure.regionprops(thresh)\n",
    "    for prop in image_proprieties: \n",
    "        X_test_simple[i,0]=np.max(prop.area)\n",
    "        X_test_simple[i,1]=np.max(prop.perimeter)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the validation feature space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_simple=np.zeros((len(img_list_prep_validation),2))\n",
    "kernelSize=4\n",
    "kernel = np.ones((kernelSize,kernelSize))\n",
    "\n",
    "for i in range(len(img_list_prep_validation)):\n",
    "    name=img_list_prep_validation[i]\n",
    "    #if i==0 : #print(name)\n",
    "    img = cv2.imread(prepared_data_path_validation+name)\n",
    "    im= cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    ret,thresh = cv2.threshold(im,100,255,cv2.THRESH_BINARY)    \n",
    "    thresh[thresh>0]=1  \n",
    "    if(np.sum(thresh>0)>2100):\n",
    "        thresh=np.zeros_like(thresh)\n",
    " \n",
    "    image_proprieties = measure.regionprops(thresh)\n",
    "    for prop in image_proprieties: \n",
    "        X_val_simple[i,0]=np.max(prop.area)\n",
    "        X_val_simple[i,1]=np.max(prop.perimeter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the training , validation and testing labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_simple=Y_train[:,4]\n",
    "Y_test_simple=Y_test[:,4]\n",
    "Y_val_simple=Y_val[:,4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepocessing: Normalizing the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "#X_train_simple = preprocessing.scale(X_train_simple)\n",
    "#X_test_simple=preprocessing.scale(X_test_simple)\n",
    "X_val_simple=preprocessing.scale(X_val_simple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Let's start with SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and hyperparameter Tuning using Cross Validation grid-search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 50, 'gamma': 1}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.831 (+/-0.086) for {'C': 0.001, 'gamma': 0.001}\n",
      "0.831 (+/-0.085) for {'C': 0.001, 'gamma': 0.01}\n",
      "0.830 (+/-0.084) for {'C': 0.001, 'gamma': 0.1}\n",
      "0.830 (+/-0.083) for {'C': 0.001, 'gamma': 1}\n",
      "0.831 (+/-0.086) for {'C': 0.01, 'gamma': 0.001}\n",
      "0.831 (+/-0.083) for {'C': 0.01, 'gamma': 0.01}\n",
      "0.830 (+/-0.082) for {'C': 0.01, 'gamma': 0.1}\n",
      "0.834 (+/-0.087) for {'C': 0.01, 'gamma': 1}\n",
      "0.831 (+/-0.083) for {'C': 0.1, 'gamma': 0.001}\n",
      "0.831 (+/-0.083) for {'C': 0.1, 'gamma': 0.01}\n",
      "0.830 (+/-0.082) for {'C': 0.1, 'gamma': 0.1}\n",
      "0.863 (+/-0.070) for {'C': 0.1, 'gamma': 1}\n",
      "0.831 (+/-0.084) for {'C': 1, 'gamma': 0.001}\n",
      "0.830 (+/-0.082) for {'C': 1, 'gamma': 0.01}\n",
      "0.850 (+/-0.077) for {'C': 1, 'gamma': 0.1}\n",
      "0.865 (+/-0.067) for {'C': 1, 'gamma': 1}\n",
      "0.831 (+/-0.083) for {'C': 10, 'gamma': 0.001}\n",
      "0.829 (+/-0.082) for {'C': 10, 'gamma': 0.01}\n",
      "0.861 (+/-0.068) for {'C': 10, 'gamma': 0.1}\n",
      "0.866 (+/-0.065) for {'C': 10, 'gamma': 1}\n",
      "0.830 (+/-0.083) for {'C': 50, 'gamma': 0.001}\n",
      "0.834 (+/-0.086) for {'C': 50, 'gamma': 0.01}\n",
      "0.863 (+/-0.068) for {'C': 50, 'gamma': 0.1}\n",
      "0.868 (+/-0.068) for {'C': 50, 'gamma': 1}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Cs = [0.001, 0.01, 0.1, 1,10,50]\n",
    "gammas = [0.001, 0.01, 0.1, 1]\n",
    "param_grid = {'C': Cs, 'gamma' : gammas}\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "print(\"# Tuning hyper-parameters\")\n",
    "print()\n",
    "clf = GridSearchCV(SVC(kernel='rbf'), param_grid, cv=5,n_jobs = -1,\n",
    "                   scoring='f1')\n",
    "clf.fit(X_train_simple,Y_train_simple)\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(clf.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Since we have also validation, let's compute the gridsearch using the validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 50, 'gamma': 0.1}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "({'C': 50, 'gamma': 0.1}, 0.9050742147048672)\n",
      "({'C': 10, 'gamma': 0.1}, 0.8994528043775649)\n",
      "({'C': 0.01, 'gamma': 1}, 0.8846560846560845)\n",
      "({'C': 10, 'gamma': 0.001}, 0.8695962843872812)\n",
      "({'C': 0.1, 'gamma': 1}, 0.8522727272727272)\n",
      "({'C': 1, 'gamma': 0.1}, 0.8420062695924765)\n",
      "({'C': 1, 'gamma': 0.001}, 0.8398835516739447)\n",
      "({'C': 10, 'gamma': 1}, 0.8367221195317314)\n",
      "({'C': 1, 'gamma': 1}, 0.8355995055624227)\n",
      "({'C': 50, 'gamma': 0.001}, 0.8282753515914139)\n",
      "({'C': 0.1, 'gamma': 0.1}, 0.8207343412526998)\n",
      "({'C': 50, 'gamma': 0.01}, 0.8165422885572139)\n",
      "({'C': 0.1, 'gamma': 0.01}, 0.8133580705009277)\n",
      "({'C': 10, 'gamma': 0.01}, 0.8104248482684755)\n",
      "({'C': 50, 'gamma': 1}, 0.7980238302818948)\n",
      "({'C': 1, 'gamma': 0.01}, 0.722177742193755)\n",
      "({'C': 0.01, 'gamma': 0.001}, 0.6775421424687329)\n",
      "({'C': 0.001, 'gamma': 0.001}, 0.6775421424687329)\n",
      "({'C': 0.1, 'gamma': 0.001}, 0.6719242902208202)\n",
      "({'C': 0.001, 'gamma': 0.01}, 0.6708004509582862)\n",
      "({'C': 0.01, 'gamma': 0.01}, 0.6608280254777069)\n",
      "({'C': 0.01, 'gamma': 0.1}, 0.6161016949152542)\n",
      "({'C': 0.001, 'gamma': 0.1}, 0.09194097616345062)\n",
      "({'C': 0.001, 'gamma': 1}, 0.031525851197982346)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from hypopt import GridSearch\n",
    "Cs = [0.001, 0.01, 0.1, 1,10,50]\n",
    "gammas = [0.001, 0.01, 0.1, 1]\n",
    "param_grid = {'C': Cs, 'gamma' : gammas}\n",
    "warnings.filterwarnings('ignore')\n",
    "opt = GridSearch(SVC(kernel='rbf'),param_grid)\n",
    "opt.fit(X_train_simple, Y_train_simple, X_val_simple, Y_val_simple, scoring='f1')\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(opt.best_params)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "for param in (opt.param_scores):\n",
    "    print(param)\n",
    "print()\n",
    "#print('Test Score for Optimized Parameters:', opt.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_method(y_true,y_pred): \n",
    "    \"\"\" Evaluating the model using f-measure and accuracy\n",
    "     Parameters\n",
    "    ----------\n",
    "        y_true  : True labels\n",
    "\n",
    "        y_pred  : Predicted labels\n",
    "                    \n",
    "    Returns : None\n",
    "    \n",
    "    \"\"\"\n",
    "    f1=metrics.f1_score(y_true, y_pred)\n",
    "    acc=metrics.accuracy_score(y_true, y_pred)\n",
    "    recall=metrics.recall_score(y_true, y_pred)\n",
    "    precision=metrics.precision_score(y_true, y_pred)\n",
    "    print(\"Recall= \",recall)\n",
    "    print(\"precision= \",precision)\n",
    "    print(\"F-measure= \",f1)\n",
    "    print(\"Accuracy= \",acc)\n",
    "    \n",
    "def plot_roc(y_true,y_pred):\n",
    "    \"\"\" Plotting Roc curve \n",
    "     Parameters\n",
    "    ----------\n",
    "        y_true  : True labels\n",
    "\n",
    "        y_pred  : Predicted labels\n",
    "                    \n",
    "    Returns : None\n",
    "    \n",
    "    \"\"\"\n",
    "    auc=roc_auc_score(y_true, y_pred)\n",
    "    print('auc=',auc)\n",
    "    fpr,tpr,_=roc_curve(y_true, y_pred)\n",
    "    plt.plot(fpr,tpr)\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    t=plt.title('Receiver operating characteristic')\n",
    "    \n",
    "def plot_prec_recall_curve(y_true, y_pred):\n",
    "    precision, recall, thresholds=precision_recall_curve(y_true, y_pred)\n",
    "    plt.plot(recall,precision)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    t=plt.title('Precision recall curve')\n",
    "    print(\"AUPR= \",average_precision_score(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's now see the model performance using the result of the cross validation grid-search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First , the result on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall=  0.8165174395296004\n",
      "precision=  0.9509727626459143\n",
      "F-measure=  0.8786310037388553\n",
      "Accuracy=  0.8872110116263531\n"
     ]
    }
   ],
   "source": [
    "clf3=SVC(C=50, kernel='rbf', gamma=1)\n",
    "clf3.fit(X_train_simple, Y_train_simple)\n",
    "y_pred_svm_content_train=clf3.predict(X_train_simple)\n",
    "evaluate_method(Y_train_simple,y_pred_svm_content_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Since we are perofming cross validation on the training set , the validation set is considered as testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall=  0.8518518518518519\n",
      "precision=  0.9527616279069767\n",
      "F-measure=  0.8994854202401372\n",
      "Accuracy=  0.9048083170890189\n"
     ]
    }
   ],
   "source": [
    "clf3=SVC(C=50, kernel='rbf', gamma=1)\n",
    "clf3.fit(X_train_simple, Y_train_simple)\n",
    "y_pred_svm_content_val=clf3.predict(X_val_simple)\n",
    "evaluate_method(Y_val_simple,y_pred_svm_content_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now the result on the testing set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall=  0.845360824742268\n",
      "precision=  0.924812030075188\n",
      "F-measure=  0.8833034111310593\n",
      "Accuracy=  0.8883161512027491\n"
     ]
    }
   ],
   "source": [
    "clf2=SVC(C=50, kernel='rbf', gamma=1)\n",
    "clf2.fit(X_train_simple, Y_train_simple)\n",
    "y_pred_svm_content=clf2.predict(X_test_simple)\n",
    "evaluate_method(Y_test_simple,y_pred_svm_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUPR=  0.8591194481047981\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_prec_recall_curve(Y_test_simple,y_pred_svm_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc= 0.8883161512027492\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_roc(Y_test_simple,y_pred_svm_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's now see the model performance using the result of the grid-search on validation data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First let's start with the result on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall=  0.7892556461312308\n",
      "precision=  0.9647174126102581\n",
      "F-measure=  0.8682102168320471\n",
      "Accuracy=  0.8801951089135374\n"
     ]
    }
   ],
   "source": [
    "clf4=SVC(C=50, kernel='rbf', gamma=0.1)\n",
    "clf4.fit(X_train_simple, Y_train_simple)\n",
    "y_pred_svm_content_train_2=clf4.predict(X_train_simple)\n",
    "evaluate_method(Y_train_simple,y_pred_svm_content_train_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### And now on testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall=  0.8367697594501718\n",
      "precision=  0.9401544401544402\n",
      "F-measure=  0.8854545454545455\n",
      "Accuracy=  0.8917525773195877\n"
     ]
    }
   ],
   "source": [
    "clf4=SVC(C=50, kernel='rbf', gamma=0.1)\n",
    "clf4.fit(X_train_simple, Y_train_simple)\n",
    "y_pred_svm_content_test_2=clf4.predict(X_test_simple)\n",
    "evaluate_method(Y_test_simple,y_pred_svm_content_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUPR=  0.868307925008956\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_prec_recall_curve(Y_test_simple,y_pred_svm_content_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc= 0.8917525773195876\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_roc(Y_test_simple,y_pred_svm_content_test_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Finding varroas by segmentation\n",
    "Add your implementation for ''**detect_by_segmentation**'' function. Please make sure the input and output follows the mentioned format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_by_segmentation(img):\n",
    "    '''\n",
    "    Input: One single image\n",
    "    Output: A numpy array containing coordonates of all detected varroas, with the following format: \n",
    "            [[x_1, y_1, w_1, h_2], [x_2, y_2, w_1, h_2], ..., [x_n, y_n, w_n, h_n]] \n",
    "            where ''n'' is the number of detected varroas.\n",
    "    '''\n",
    "\n",
    "    #Your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add your implementation. Report the Precision, Recall and F1-score, by using all 50 images of the test-set, and considering 0.3 as the IoU threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Implement your first detector\n",
    "\n",
    "Write your function(s) for the second part. Feel free to change the name of the function and add your additional functions, but please make sure their input and output follows the mentioned format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_data_path_unseen = './project-data/images/test/unseen/'\n",
    "def split_and_label(prepared_data_path_unseen,img,img_name): \n",
    "    #Mirror padding\n",
    "    w,h,d = img.shape \n",
    "    w_i=int(w/48)+1\n",
    "    h_i=int(h/48)+1\n",
    "    new_w=w_i*48\n",
    "    new_h=h_i*48\n",
    "    count=0\n",
    "    new_img=img\n",
    "    for i in range(w_i): \n",
    "        for j in range(h_i): \n",
    "            count+=1 \n",
    "            name=img_name+\"_\"+str(count)\n",
    "            sub_img=new_img[0:48,0:48,:]    \n",
    "            im=Image.fromarray(sub_img)\n",
    "            b, g, r = im.split()\n",
    "            im= Image.merge(\"RGB\", (r, g, b))\n",
    "            im.save(prepared_data_path_unseen+name+\".jpg\")         \n",
    "            new_img=np.roll(new_img,-48,axis=1)\n",
    "        new_img=np.roll(new_img,-48,axis=0)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_by_method_1(img,name):\n",
    "    '''\n",
    "    Input: One single image\n",
    "    Output: A numpy array containing coordonates of all detected varroas, with the following format: \n",
    "            [[x_1, y_1, w_1, h_2], [x_2, y_2, w_1, h_2], ..., [x_n, y_n, w_n, h_n]] \n",
    "            where ''n'' is the number of detected varroas.\n",
    "    '''\n",
    "    split_and_label(prepared_data_path_unseen,img,name)\n",
    "    img_list_dir_unseen = os.listdir(prepared_data_path_unseen)\n",
    "    img_list_unseen = [names for names in img_list_dir_unseen  if names.endswith(\".jpg\")]\n",
    "    X_val_unseen=np.zeros((len(img_list_unseen),2))\n",
    "    kernelSize=4\n",
    "    kernel = np.ones((kernelSize,kernelSize))\n",
    "\n",
    "    for i in range(len(img_list_unseen)):\n",
    "        name=img_list_unseen[i]\n",
    "        #if i==0 : #print(name)\n",
    "        img = cv2.imread(prepared_data_path_unseen+name)\n",
    "        im= cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        ret,thresh = cv2.threshold(im,100,255,cv2.THRESH_BINARY)    \n",
    "        thresh[thresh>0]=1  \n",
    "        if(np.sum(thresh>0)>2150):\n",
    "            thresh=np.zeros_like(thresh)\n",
    "        #plt.figure()\n",
    "        #plt.imshow(thresh)\n",
    "        image_proprieties = measure.regionprops(thresh)\n",
    "        for prop in image_proprieties: \n",
    "            X_val_unseen[i,0]=np.max(prop.area)\n",
    "            X_val_unseen[i,1]=np.max(prop.perimeter)\n",
    "    return X_val_unseen\n",
    "    #Your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "metadata": {},
   "outputs": [],
   "source": [
    "name=img_list_test[1]\n",
    "im=cv2.imread(src_path_test+name)\n",
    "X_val_unseen=detect_by_method_1(im,name)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_unseen=preprocessing.scale(X_val_unseen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_unseen=clf4.predict(X_val_unseen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 727,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-41.0"
      ]
     },
     "execution_count": 727,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_unseen.sum()-1554"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add your implementation. Report the Precision, Recall and F1-score, by using all 50 images of the test-set, and considering 0.3 as the IoU threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Using MLP and CNNs\n",
    "\n",
    "Add your implementation for the thrid part. Feel free to add your desirable functions, but please make sure you have proper functions for the final detection, where their input and output follows the same format as the previous parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "You can generate a json submission file by using the function ''**generate_pred_json**''. This prediction file can be uploaded online for evaluation (Please refer to section 3 of the project description for more details)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "\n",
    "def generate_pred_json(data, tag='baseline'):\n",
    "    '''\n",
    "    Input\n",
    "    - data: Is a dictionary d, such that:\n",
    "          d = { \n",
    "              \"ID_1\": [], \n",
    "              \"ID_2\": [[x_21, y_21, w_21, h_21], [x_22, y_22, w_22, h_22]], \n",
    "              ... \n",
    "              \"ID_i\": [[x_i1, y_i1, w_i1, h_i1], ..., [x_iJ, y_iJ, w_iJ, h_iJ]],\n",
    "              ... \n",
    "              \"ID_N\": [[x_N1, y_N1, w_N1, h_N1]],\n",
    "          }\n",
    "          where ID is the string id of the image (e.i. 5a05e86fa07d56baef59b1cb_32.00px_1) and the value the Kx4 \n",
    "          array of intergers for the K predicted bounding boxes (e.g. [[170, 120, 15, 15]])\n",
    "    - tag: (optional) string that will be added to the name of the json file.\n",
    "    Output\n",
    "      Create a json file, \"prediction_[tag].json\", conatining the prediction to EvalAI format.\n",
    "    '''\n",
    "    unvalid_key = []\n",
    "    _data = data.copy()\n",
    "    for key, value in _data.items():\n",
    "        try:\n",
    "            # Try to convert to numpy array and cast as closest int\n",
    "            print(key)\n",
    "            v = np.around(np.array(value)).astype(int)\n",
    "            # Check is it is a 2d array with 4 columns (x,y,w,h)\n",
    "            if v.ndim != 2 or v.shape[1] != 4:\n",
    "                unvalid_key.append(key)\n",
    "            # Id must be a string\n",
    "            if not isinstance(key, str):\n",
    "                unvalid_key.append(key)\n",
    "            _data[key] = v.tolist()\n",
    "        # Deal with not consistant array size and empty predictions\n",
    "        except (ValueError, TypeError):\n",
    "            unvalid_key.append(key)\n",
    "    # Remove unvalid key from dictionnary\n",
    "    for key in unvalid_key: del _data[key]\n",
    "    \n",
    "    with open('prediction_{}.json'.format(tag), 'w') as outfile:\n",
    "        json.dump(_data, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 903,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800"
      ]
     },
     "execution_count": 903,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_list_dir_unseen = os.listdir(src_path_train)\n",
    "img_list_unseen = [names for names in img_list_dir_unseen  if names.endswith(\".jpg\")]\n",
    "len(img_list_unseen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 917,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 48, 48)"
      ]
     },
     "execution_count": 917,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h=np.zeros((1,48,48))\n",
    "h2=np.zeros((48,48))\n",
    "h[0]=h2\n",
    "h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 918,
   "metadata": {},
   "outputs": [],
   "source": [
    "def box_intersection_over_union(boxA, boxB):\n",
    "    #determine the (x, y)-coordinates of the intersection rectangle\n",
    "    boxA=[boxA[0],boxA[1],boxA[0]+boxA[2],boxA[1]+boxA[3]]\n",
    "    boxB=[boxB[0],boxB[1],boxB[0]+boxB[2],boxB[1]+boxB[3]]\n",
    "    xA = max(boxA[0], boxB[0])\n",
    "    yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[2], boxB[2])\n",
    "    yB = min(boxA[3], boxB[3])\n",
    "    # compute the area of intersection rectangle\n",
    "    interArea = max(0, xB - xA + 1) * max(0, yB - yA + 1)\n",
    "    # compute the area of both the prediction and ground-truth\n",
    "    boxAArea = (boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1)\n",
    "    boxBArea = (boxB[2] - boxB[0] + 1) * (boxB[3] - boxB[1] + 1)\n",
    " \n",
    "    # compute the intersection over union by taking the intersection\n",
    "    # area and dividing it by the sum of prediction + ground-truth\n",
    "    # areas - the interesection area\n",
    "    iou = interArea / float(boxAArea + boxBArea - interArea)\n",
    "    \n",
    "    return iou\n",
    "def compute_iou(ground_truth,predicted_varroa):\n",
    "    iou=-1*np.zeros((len(ground_truth),len(predicted_varroa)))\n",
    "    for i in range(len(ground_truth)): \n",
    "        for j in range(len(predicted_varroa)):\n",
    "            iou[i,j]=box_intersection_over_union(ground_truth[i],predicted_varroa[j])\n",
    "   \n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 948,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_name=random.choice(img_list)\n",
    "annotations_xmls = [parse_file(os.path.join(xml_path_train, img_name[:-4]) + '.xml') ]\n",
    "\n",
    "ground_truth=[]\n",
    "for i in range(len(annotations_xmls)): \n",
    "    ground_truth.append(annotations_xmls[0][i]['bbox'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 950,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[522, 25, 29, 30]"
      ]
     },
     "execution_count": 950,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 960,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (48,48,3) into shape (3,48,48)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-960-8694669a0fec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mannotations_xmls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mparse_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxml_path_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_name\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'.xml'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0mreshape_window\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwindow\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[0mground_truth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mannotations_xmls\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not broadcast input array from shape (48,48,3) into shape (3,48,48)"
     ]
    }
   ],
   "source": [
    "false_positive=0\n",
    "while (false_positive<6500):\n",
    "    (winW, winH) = (48, 48)\n",
    "    iou=0\n",
    "    img_name=random.choice(img_list)\n",
    "    im=cv2.imread(src_path_train+img_name)\n",
    "    count=0\n",
    "    for (x, y, window) in sliding_window(im, stepSize=48, windowSize=(winW, winH)):\n",
    "        reshape_window=np.zeros((1,48,48,3))\n",
    "        # if the window does not meet our desired window size, ignore it\n",
    "        if window.shape[0] != winH or window.shape[1] != winW:\n",
    "            continue\n",
    "        annotations_xmls = [parse_file(os.path.join(xml_path_train, img_name[:-4]) + '.xml') ]\n",
    "        \n",
    "        reshape_window[0]=window\n",
    "        ground_truth=[]\n",
    "        for i in range(len(annotations_xmls[0])): \n",
    "            ground_truth.append(annotations_xmls[0][i]['bbox'])\n",
    "        iou=compute_iou(ground_truth,[[x,y,48,48]])\n",
    "        if iou.any()>0.3:\n",
    "            continue\n",
    "        reshape_window_mean = np.mean(reshape_window,axis=(0,1,2)).reshape((1,1,1,-1))\n",
    "        reshape_window_std = np.std(reshape_window,axis=(0,1,2)).reshape((1,1,1,-1))\n",
    "        reshape_window = (reshape_window - reshape_window_mean) / reshape_window_std #.reshape(num_imgs, -1)\n",
    "        if(reshape_window.shape[1]!=3):\n",
    "            reshape_window = reshape_window.transpose((0,3,1,2))\n",
    "        # Predict bounding boxes on the train images.\n",
    "        with torch.no_grad():\n",
    "            pred_y_val_box_unseen, pred_y_val_logit_unseen = net.forward(torch.tensor(reshape_window, dtype=torch.float32))\n",
    "            pred_y_val_box_unseen, pred_y_val_logit_unseen = pred_y_val_box_unseen.numpy(), pred_y_val_logit_unseen.numpy()\n",
    "            pred_y_val_label_unseen = pred_y_val_logit_unseen>0.5\n",
    "            pred_bboxes_val_unseen = pred_y_val_box_unseen\n",
    "            pred_bboxes_val_unseen = pred_bboxes_val_unseen.reshape(len(pred_bboxes_val_unseen), 1, -1)\n",
    "        if pred_y_val_label_unseen==1:\n",
    "            im=Image.fromarray(window)\n",
    "            b, g, r = im.split()\n",
    "            im= Image.merge(\"RGB\", (r, g, b))\n",
    "            im.save(fp_data_path+img_name[:-4]+\"_\"+str(count)+\"_0.jpg\")   \n",
    "            count=count+1\n",
    "            false_positive=false_positive+1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 865,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_unseen_=np.zeros((len(img_list_unseen),48,48,3))\n",
    "for i in range(len(img_list_unseen)):\n",
    "    name=img_list_unseen[i]\n",
    "    img = cv2.imread(prepared_data_path_unseen+name)\n",
    "    X_val_unseen_[i,:,:,:]=img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 866,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[212.06688321 196.45453824 179.69004124]]]] [[[[48.53473396 44.58857915 38.80400043]]]]\n"
     ]
    }
   ],
   "source": [
    "imgs_mean_val_unseen = np.mean(X_val_unseen_,axis=(0,1,2)).reshape((1,1,1,-1))\n",
    "imgs_std_val_unseen = np.std(X_val_unseen_,axis=(0,1,2)).reshape((1,1,1,-1))\n",
    "print(imgs_mean_val_unseen,imgs_std_val_unseen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 867,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1476, 48, 48, 3) 1.3742116169504597e-16 0.9999999999981006\n"
     ]
    }
   ],
   "source": [
    "X_val_unseen_ = (X_val_unseen_ - imgs_mean_val_unseen) / imgs_std_val_unseen #.reshape(num_imgs, -1)\n",
    "print(X_val_unseen_.shape, np.mean(X_val_unseen_), np.std(X_val_unseen_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 868,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1476, 48, 48, 3)"
      ]
     },
     "execution_count": 868,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val_unseen_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 869,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48, 48, 3)"
      ]
     },
     "execution_count": 869,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val_unseen_[0,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 900,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(X_val_unseen_.shape[1]!=3):\n",
    "    X_val_unseen_ = X_val_unseen_.transpose((0,3,1,2))\n",
    "# Predict bounding boxes on the train images.\n",
    "with torch.no_grad():\n",
    "    pred_y_val_box_unseen, pred_y_val_logit_unseen = net.forward(torch.tensor(X_val_unseen_, dtype=torch.float32))\n",
    "    pred_y_val_box_unseen, pred_y_val_logit_unseen = pred_y_val_box_unseen.numpy(), pred_y_val_logit_unseen.numpy()\n",
    "    pred_y_val_label_unseen = pred_y_val_logit_unseen>0.5\n",
    "    pred_bboxes_val_unseen = pred_y_val_box_unseen\n",
    "    pred_bboxes_val_unseen = pred_bboxes_val_unseen.reshape(len(pred_bboxes_val_unseen), 1, -1)\n",
    "    #pred_bboxes_val_unseen.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 901,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1415"
      ]
     },
     "execution_count": 901,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(pred_y_val_label_unseen).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 874,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "217"
      ]
     },
     "execution_count": 874,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(annotations_xmls_test[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 763,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       ...,\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True]])"
      ]
     },
     "execution_count": 763,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_y_val_label_unseen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 877,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1539"
      ]
     },
     "execution_count": 877,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=0\n",
    "for i in range(150):\n",
    "    a=a+(len(annotations_xmls_validation[i]))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 876,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(image, stepSize, windowSize):\n",
    "    # slide a window across the image\n",
    "    for y in range(0, image.shape[0], stepSize):\n",
    "        for x in range(0, image.shape[1], stepSize):\n",
    "            # yield the current window\n",
    "            yield (x, y, image[y:y + windowSize[1], x:x + windowSize[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 863,
   "metadata": {},
   "outputs": [],
   "source": [
    "(winW, winH) = (48, 48)\n",
    "\n",
    "img_name=img_list_test[1]\n",
    "im=cv2.imread(src_path_test+img_name)\n",
    "count=0\n",
    "for (x, y, window) in sliding_window(im, stepSize=48, windowSize=(winW, winH)):\n",
    "    # if the window does not meet our desired window size, ignore it\n",
    "    if window.shape[0] != winH or window.shape[1] != winW:\n",
    "        continue\n",
    "    name=img_name+\"_\"+str(count)\n",
    "    im=Image.fromarray(window)\n",
    "    b, g, r = im.split()\n",
    "    im= Image.merge(\"RGB\", (r, g, b))\n",
    "    im.save(prepared_data_path_unseen+name+\".jpg\")   \n",
    "    count=count+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
